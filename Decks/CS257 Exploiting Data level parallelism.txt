--
what is the advantage of vector processing
-
reduce number of fetches per execution, can process multiple instrucitons at once
--
what is the three step programmers model
-
Transfer sets of data elements to sequential “register” files,Operate on data in register files,
Place results back into memory
--
what are register files
-
compiler managed buffers for data
--
what are vector registers
-
fixed length buffers to store a single vector e.g. cray 1 incorporated 8 vector registers where each vector held 64 elements of 64bits
--
what are the components of the vector architecture
-
vector functional units (are pipelined), scalar registers (used to compute addresses for vectors), vector load store unit (used regardless of vector or floating point operation)
--
what factors effect vector unit execution time
-
length of vector operands,structural hazards among operations,data dependancies
--
what is a convoy
-
a set of vector instrucitons that could execute simulatneously on the same clock cycle
--
what is flexible chaining
-
Flexible chaining allows a vector instruction to chain to (almost) any other active
vector instruction
--
what is a lane
-
a parallel pipeline of vector register logic
--
what is a chime
-
a measurement of convoy execution performance
--
what are the different optimisations we can make on vector registers
-
multiple lanes,vector length registers,vector mask registers,memory banking
--
what does the vector length register do
-
keeps track of how long of a vector the vector register can take
--
what happens if the vector at runtime has too much data for the vector register
-
strip mining: generates additional code such that each vector operation is an acceptable size, an additional loop is created to handle remaining iterations
--
what are vector mask registers
-
vectors which provide conditional execution for each item in a vector unit
--
how does memory banking help vector execution
-
allows all members of a vector to be loaded at the same time
--
what are the four appealing characteristics to SIMD vector instrucitons
-
Low cost to incorporate,Requires little extra state (competed to vector architectures) 
- increased state implied extended context switch times,Requires less memory bandwidth than vector architectures,
No virtual memory problems relating to cross-page access and page-faults
--
what are the tiers of parallelism
-
thread (associated with each data element), blocks (groups of threads),grids (groups of blocks)
--
what are the challenges of GPU programming
-
Scheduling of computation on the system processor and GPU,
Transferring data between system memory and GPU memory
--
